# Google Cloud Build configuration
# Handles both harvest (daily) and newsletter (Tue/Thu/Sat)
# cloudbuild.yaml (minimal: setup + cleanup)

steps:
  # 1) Setup: only workspace prep (LFS + DB)
  - name: 'python:3.10'
    id: 'setup'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üöÄ Starting pipeline..."
        apt-get update -y && apt-get install -y git-lfs
        git lfs install --force

        # Ensure both branches exist locally and are up to date
        git fetch --prune origin +refs/heads/*:refs/remotes/origin/*

        # Pull DB from data, then place it in working tree on main
        git checkout -B data refs/remotes/origin/data
        git lfs pull --include="newsletter.db"
        cp newsletter.db /tmp/newsletter.db
        git checkout -B main refs/remotes/origin/main
        cp /tmp/newsletter.db newsletter.db
        ls -lh newsletter.db

        echo "Setup complete ‚úÖ"

  # 3) Harvest (trigger: _TRIGGER_TYPE=harvest)
  - name: 'python:3.10'
    id: 'harvest'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
    args:
      - '-c'
      - |
        if [ "$_TRIGGER_TYPE" != "harvest" ]; then
          echo "‚è≠Ô∏è Skipping harvest"; exit 0
        fi

        # Export the secret as a regular environment variable for Python
        export YOUTUBE_API_KEY="$$_YOUTUBE_API_KEY"
        
        # Debug: Check if the key is being set (shows length, not the actual key)
        echo "YOUTUBE_API_KEY length: ${#YOUTUBE_API_KEY}"

        apt-get update -y && apt-get install -y git-lfs
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace

        python -m pip install --upgrade pip
        pip install -r requirements.txt

        if [ ! -f newsletter.db ]; then
          python -m src.init_db
        fi

        python -m src.articles.run_harvest
        python -m src.youtube.youtube_scraper

        cp newsletter.db /tmp/newsletter_updated.db
        rm -f newsletter.db

        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install

        cp /tmp/newsletter_updated.db newsletter.db
        git add newsletter.db || true
        git commit -m "Daily harvest $(date --iso-8601=seconds)" || echo "No changes"

        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:$$_GITHUB_TOKEN@github.com/$$_GITHUB_REPO.git"
        git push push-tmp data

        echo "‚úÖ Harvest complete!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YOUTUBE_API_KEY']

  # # 4) Newsletter (trigger: _TRIGGER_TYPE=newsletter)
  # - name: 'python:3.10'
  #   id: 'newsletter'
  #   entrypoint: 'bash'
  #   env:
  #     - 'PYTHONPATH=/workspace'
  #     - 'SMTP_HOST=smtp.gmail.com'
  #     - 'SMTP_PORT=587'
  #   args:
  #     - '-c'
  #     - |
  #       if [ "$_TRIGGER_TYPE" != "newsletter" ]; then
  #         echo "‚è≠Ô∏è Skipping newsletter"; exit 0
  #       fi

  #       # In the newsletter step, add these exports:
  #       export OPENROUTER_API_KEY="$$_OPENROUTER_API_KEY"
  #       export YOUTUBE_API_KEY="$$_YOUTUBE_API_KEY"
  #       export SMTP_USER="$$_SMTP_USER"
  #       export SMTP_PASS="$$_SMTP_PASS"

  #       apt-get update -y && apt-get install -y git-lfs tor
  #       git lfs install
  #       git config --global user.email "bot@github.com"
  #       git config --global user.name "Newsletter Bot"
  #       git config --global --add safe.directory /workspace

  #       python -m pip install --upgrade pip
  #       pip install -r requirements.txt
  #       pip install -U yt-dlp

  #       rm -f newsletter.db || true
  #       git fetch origin data
  #       git checkout data
  #       git lfs pull --include="newsletter.db"
  #       cp newsletter.db /tmp/newsletter.db
  #       git checkout main
  #       cp /tmp/newsletter.db newsletter.db
  #       ls -lh newsletter.db

  #       python -m src.init_db

  #       echo "$$_YT_COOKIES_B64" | base64 --decode > cookies.txt
  #       export YT_COOKIE_FILE="$(pwd)/cookies.txt"

  #       echo 'ControlPort 9051' >> /etc/tor/torrc
  #       service tor start
  #       sleep 12

  #       python -m src.articles.embed_articles
  #       python -m src.articles.rank
  #       python -m src.articles.summarise
  #       python -m src.youtube.embed_videos
  #       python -m src.youtube.youtube_rank
  #       python -m src.youtube.youtube_summarise
  #       python -m src.render_newsletter
  #       python -m src.smtp_mailer
  #       python -m src.housekeeping

  #       echo "üìä Database after housekeeping:"; ls -lh newsletter.db

  #       cp newsletter.db /tmp/newsletter_cleared.db
  #       rm -f newsletter.db

  #       git fetch origin data
  #       git checkout data
  #       git pull --ff-only origin data
  #       git lfs install
  #       cp /tmp/newsletter_cleared.db newsletter.db

  #       git add newsletter.db || true
  #       git commit -m "Cleared DB after newsletter $(date --iso-8601=seconds)" || true

  #       git remote remove push-tmp 2>/dev/null || true
  #       git remote add push-tmp "https://oauth2:$$_GITHUB_TOKEN@github.com/$$_GITHUB_REPO.git"
  #       git push push-tmp data

  #       echo "‚úÖ Newsletter complete and DB cleared!"
  #   secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YT_COOKIES_B64', '_OPENROUTER_API_KEY', '_YOUTUBE_API_KEY', '_SMTP_USER', '_SMTP_PASS']

    # Newsletter step - Fixed to avoid git conflicts
  - name: 'python:3.10'
    id: 'newsletter'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
      - 'SMTP_HOST=smtp.gmail.com'
      - 'SMTP_PORT=587'
    args:
      - '-c'
      - |
        if [ "$_TRIGGER_TYPE" != "newsletter" ]; then
          echo "‚è≠Ô∏è Skipping newsletter"; exit 0
        fi

        echo "üì∞ Starting newsletter generation..."

        # Export all environment variables
        export OPENROUTER_API_KEY="$$_OPENROUTER_API_KEY"
        export YOUTUBE_API_KEY="$$_YOUTUBE_API_KEY"
        export SMTP_USER="$$_SMTP_USER"
        export SMTP_PASS="$$_SMTP_PASS"

        # Install dependencies
        apt-get update -y && apt-get install -y git-lfs tor
        git lfs install --force
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace

        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -U yt-dlp

        # Create Python package files
        touch src/__init__.py
        touch src/articles/__init__.py  
        touch src/youtube/__init__.py

        # Check if we have source files
        echo "Source files check:"
        ls -la src/ || echo "ERROR: No src directory!"
        
        # Database should already be available from setup step
        if [ ! -f newsletter.db ]; then
          echo "ERROR: No newsletter.db found"
          exit 1
        fi
        
        echo "Database size before processing:"
        ls -lh newsletter.db

        # Initialize database schema
        python -m src.init_db

        # Set up YouTube cookies
        echo "$$_YT_COOKIES_B64" | base64 --decode > cookies.txt
        export YT_COOKIE_FILE="$(pwd)/cookies.txt"

        # Start Tor
        echo 'ControlPort 9051' >> /etc/tor/torrc
        service tor start
        sleep 12

        # Run newsletter pipeline
        echo "Running article processing..."
        python -m src.articles.embed_articles
        python -m src.articles.rank
        python -m src.articles.summarise
        
        echo "Running video processing..."
        python -m src.youtube.embed_videos
        python -m src.youtube.youtube_rank
        python -m src.youtube.youtube_summarise
        
        echo "Rendering and sending newsletter..."
        python -m src.render_newsletter
        python -m src.smtp_mailer
        
        echo "Running housekeeping..."
        python -m src.housekeeping

        echo "üìä Database after housekeeping:"
        ls -lh newsletter.db

        # Save the processed database for the next step
        cp newsletter.db /tmp/newsletter_final.db

        echo "‚úÖ Newsletter processing complete!"
    secretEnv: ['_YT_COOKIES_B64', '_OPENROUTER_API_KEY', '_YOUTUBE_API_KEY', '_SMTP_USER', '_SMTP_PASS']

  # Separate step just for saving the database back
  - name: 'python:3.10'
    id: 'save-newsletter-db'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if [ "$_TRIGGER_TYPE" != "newsletter" ]; then
          echo "‚è≠Ô∏è Skipping database save"; exit 0
        fi

        echo "üíæ Saving processed database to data branch..."
        
        # Configure git
        apt-get update -y && apt-get install -y git-lfs
        git lfs install --force
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        
        # Get the processed database
        if [ ! -f /tmp/newsletter_final.db ]; then
          echo "ERROR: No processed database found"
          exit 1
        fi

        # Clone fresh repo to avoid conflicts
        cd /tmp
        git clone "https://oauth2:$$_GITHUB_TOKEN@github.com/$$_GITHUB_REPO.git" fresh-repo
        cd fresh-repo
        
        git fetch origin
        git checkout data
        git lfs pull --include="newsletter.db"
        
        # Replace with processed database
        cp /tmp/newsletter_final.db newsletter.db
        
        echo "Final database size:"
        ls -lh newsletter.db
        
        git add newsletter.db
        git commit -m "Newsletter processed DB $(date --iso-8601=seconds)" || echo "No changes"
        git push origin data

        echo "‚úÖ Database saved to data branch!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO']

# Secrets
availableSecrets:
  secretManager:
    - versionName: projects/${PROJECT_ID}/secrets/github-token/versions/latest
      env: '_GITHUB_TOKEN'
    - versionName: projects/${PROJECT_ID}/secrets/github-repo/versions/latest
      env: '_GITHUB_REPO'
    - versionName: projects/${PROJECT_ID}/secrets/YT_COOKIES_MIN_B64/versions/latest
      env: '_YT_COOKIES_B64'
    - versionName: projects/${PROJECT_ID}/secrets/OPENROUTER_API_KEY/versions/latest
      env: '_OPENROUTER_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/YOUTUBE_API_KEY/versions/latest
      env: '_YOUTUBE_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_USER/versions/latest
      env: '_SMTP_USER'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_PASS/versions/latest
      env: '_SMTP_PASS'

options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  volumes:
    - name: pip-cache
      path: /root/.cache/pip

timeout: 3600s
