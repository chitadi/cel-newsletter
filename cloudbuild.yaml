# Google Cloud Build configuration
# Handles both harvest (daily) and newsletter (Tue/Thu/Sat)

steps:
  - name: 'python:3.10'
    id: 'setup'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ðŸš€ Starting pipeline (Trigger: ${_TRIGGER_TYPE})..."
  
        # Install git-lfs only to be able to pull the DB
        apt-get update -y && apt-get install -y git-lfs
        git lfs install --force
  
        # (Optional) ensure src is a proper package if not committed yet
        touch src/__init__.py src/articles/__init__.py src/youtube/__init__.py || true
  
        # Get DB from GitHub data branch
        git fetch origin data
        git checkout data
        git lfs pull --include="newsletter.db"
        cp newsletter.db /tmp/newsletter.db
        git checkout main
        cp /tmp/newsletter.db newsletter.db
        ls -lh newsletter.db
  
        echo "Setup complete âœ…"
      secretEnv: ['_GITHUB_TOKEN']

 - name: 'python:3.10'
    id: 'cleanup'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
    args:
      - '-c'
      - |
        if [[ "${_TRIGGER_TYPE}" != "cleanup" ]]; then
          echo "â­ï¸ Skipping cleanup"; exit 0
        fi
  
        echo "ðŸ§¹ Starting database cleanup..."
  
        # Fail fast on missing secrets
        [[ -n "${_GITHUB_TOKEN:-}" ]] || { echo "âŒ _GITHUB_TOKEN missing"; exit 1; }
        [[ -n "${_GITHUB_REPO:-}"  ]] || { echo "âŒ _GITHUB_REPO missing (owner/repo)"; exit 1; }
  
        # Fresh container â†’ install deps again
        apt-get update -y && apt-get install -y git-lfs
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace
  
        python -m pip install --upgrade pip
        pip install -r requirements.txt
  
        echo "ðŸ“Š Database BEFORE cleanup:"; ls -lh newsletter.db || true
  
        # Run housekeeping
        python -m src.housekeeping || { echo "âš ï¸ Housekeeping failed; continuing"; }
  
        echo "ðŸ“Š Database AFTER cleanup:"; ls -lh newsletter.db || true
  
        # Prepare commit to data branch
        cp newsletter.db /tmp/newsletter_cleared.db || true
        rm -f newsletter.db
  
        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install
  
        cp /tmp/newsletter_cleared.db newsletter.db || true
        echo "ðŸ“Š Final database size in data branch:"; ls -lh newsletter.db || true
  
        git add newsletter.db || true
        git commit -m "Database cleanup $(date --iso-8601=seconds)" || echo "âš ï¸ No changes to commit"
  
        # Push with token (avoid credential helpers)
        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:${_GITHUB_TOKEN}@github.com/${_GITHUB_REPO}.git"
        git push push-tmp data
  
        echo "âœ… Cleanup complete!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO']
    volumes:
      - name: pip-cache
        path: /root/.cache/pip


 - name: 'python:3.10'
    id: 'harvest'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
      - 'YOUTUBE_API_KEY=${_YOUTUBE_API_KEY}'
    args:
      - '-c'
      - |
        if [[ "${_TRIGGER_TYPE}" != "harvest" ]]; then
          echo "â­ï¸ Skipping harvest"; exit 0
        fi
  
        apt-get update -y && apt-get install -y git-lfs
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace
  
        python -m pip install --upgrade pip
        pip install -r requirements.txt
  
        if [ ! -f newsletter.db ]; then
          python -m src.init_db
        fi
  
        python -m src.articles.run_harvest
        python -m src.youtube.youtube_scraper
  
        cp newsletter.db /tmp/newsletter_updated.db
        rm -f newsletter.db
  
        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install
  
        cp /tmp/newsletter_updated.db newsletter.db
        git add newsletter.db || true
        git commit -m "Daily harvest $(date --iso-8601=seconds)" || echo "No changes"
  
        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:${_GITHUB_TOKEN}@github.com/${_GITHUB_REPO}.git"
        git push push-tmp data
  
        echo "âœ… Harvest complete!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YOUTUBE_API_KEY']
    volumes:
      - name: pip-cache
        path: /root/.cache/pip

 - name: 'python:3.10'
    id: 'newsletter'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
      - 'SMTP_HOST=smtp.gmail.com'
      - 'SMTP_PORT=587'
    args:
      - '-c'
      - |
        if [[ "${_TRIGGER_TYPE}" != "newsletter" ]]; then
          echo "â­ï¸ Skipping newsletter"; exit 0
        fi
  
        apt-get update -y && apt-get install -y git-lfs tor
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace
  
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -U yt-dlp
  
        # Fresh DB from data branch
        rm -f newsletter.db || true
        git fetch origin data
        git checkout data
        git lfs pull --include="newsletter.db"
        cp newsletter.db /tmp/newsletter.db
        git checkout main
        cp /tmp/newsletter.db newsletter.db
        ls -lh newsletter.db
  
        python -m src.init_db
  
        # YouTube cookies
        echo "${_YT_COOKIES_B64}" | base64 --decode > cookies.txt
        export YT_COOKIE_FILE="$(pwd)/cookies.txt"
  
        # Tor
        echo 'ControlPort 9051' >> /etc/tor/torrc
        service tor start
        sleep 12
  
        # Pipeline
        python -m src.articles.embed_articles
        python -m src.articles.rank
        python -m src.articles.summarise
        python -m src.youtube.embed_videos
        python -m src.youtube.youtube_rank
        python -m src.youtube.youtube_summarise
        python -m src.render_newsletter
        python -m src.smtp_mailer
        python -m src.housekeeping
  
        echo "ðŸ“Š Database after housekeeping:"; ls -lh newsletter.db
  
        # Commit cleared DB back to data
        cp newsletter.db /tmp/newsletter_cleared.db
        rm -f newsletter.db
        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install
        cp /tmp/newsletter_cleared.db newsletter.db
  
        git add newsletter.db || true
        git commit -m "Cleared DB after newsletter $(date --iso-8601=seconds)" || true
  
        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:${_GITHUB_TOKEN}@github.com/${_GITHUB_REPO}.git"
        git push push-tmp data
  
        echo "âœ… Newsletter complete and DB cleared!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YT_COOKIES_B64', '_OPENROUTER_API_KEY', '_YOUTUBE_API_KEY', '_SMTP_USER', '_SMTP_PASS']
    volumes:
      - name: pip-cache
        path: /root/.cache/pip

# Define secrets from Secret Manager
availableSecrets:
  secretManager:
    - versionName: projects/${PROJECT_ID}/secrets/github-token/versions/latest
      env: '_GITHUB_TOKEN'
    - versionName: projects/${PROJECT_ID}/secrets/github-repo/versions/latest
      env: '_GITHUB_REPO'
    - versionName: projects/${PROJECT_ID}/secrets/YT_COOKIES_MIN_B64/versions/latest
      env: '_YT_COOKIES_B64'
    - versionName: projects/${PROJECT_ID}/secrets/OPENROUTER_API_KEY/versions/latest
      env: '_OPENROUTER_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/YOUTUBE_API_KEY/versions/latest
      env: '_YOUTUBE_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_USER/versions/latest
      env: '_SMTP_USER'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_PASS/versions/latest
      env: '_SMTP_PASS'

options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  volumes:
    - name: pip-cache
      path: /root/.cache/pip
timeout: 3600s  # 1 hour timeout
