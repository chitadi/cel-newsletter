# Google Cloud Build configuration
# Handles both harvest (daily) and newsletter (Tue/Thu/Sat)
# cloudbuild.yaml (minimal: setup + cleanup)

steps:
  # 1) Setup: only workspace prep (LFS + DB)
  - name: 'python:3.10'
    id: 'setup'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "🚀 Starting pipeline..."
        apt-get update -y && apt-get install -y git-lfs
        git lfs install --force

        # Ensure both branches exist locally and are up to date
        git fetch --prune origin +refs/heads/*:refs/remotes/origin/*

        # Pull DB from data, then place it in working tree on main
        git checkout -B data refs/remotes/origin/data
        git lfs pull --include="newsletter.db"
        cp newsletter.db /tmp/newsletter.db
        git checkout -B main refs/remotes/origin/main
        cp /tmp/newsletter.db newsletter.db
        ls -lh newsletter.db

        echo "Setup complete ✅"

  # 3) Harvest (trigger: _TRIGGER_TYPE=harvest)
  - name: 'python:3.10'
    id: 'harvest'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
      - 'YOUTUBE_API_KEY=${_YOUTUBE_API_KEY}'
    args:
      - '-c'
      - |
        if [ "$_TRIGGER_TYPE" != "harvest" ]; then
          echo "⏭️ Skipping harvest"; exit 0
        fi

        apt-get update -y && apt-get install -y git-lfs
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace

        python -m pip install --upgrade pip
        pip install -r requirements.txt

        if [ ! -f newsletter.db ]; then
          python -m src.init_db
        fi

        python -m src.articles.run_harvest
        python -m src.youtube.youtube_scraper

        cp newsletter.db /tmp/newsletter_updated.db
        rm -f newsletter.db

        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install

        cp /tmp/newsletter_updated.db newsletter.db
        git add newsletter.db || true
        git commit -m "Daily harvest $(date --iso-8601=seconds)" || echo "No changes"

        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:$$_GITHUB_TOKEN@github.com/$$_GITHUB_REPO.git"
        git push push-tmp data

        echo "✅ Harvest complete!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YOUTUBE_API_KEY']

  # 4) Newsletter (trigger: _TRIGGER_TYPE=newsletter)
  - name: 'python:3.10'
    id: 'newsletter'
    entrypoint: 'bash'
    env:
      - 'PYTHONPATH=/workspace'
      - 'SMTP_HOST=smtp.gmail.com'
      - 'SMTP_PORT=587'
    args:
      - '-c'
      - |
        if [ "$_TRIGGER_TYPE" != "newsletter" ]; then
          echo "⏭️ Skipping newsletter"; exit 0
        fi

        apt-get update -y && apt-get install -y git-lfs tor
        git lfs install
        git config --global user.email "bot@github.com"
        git config --global user.name "Newsletter Bot"
        git config --global --add safe.directory /workspace

        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -U yt-dlp

        rm -f newsletter.db || true
        git fetch origin data
        git checkout data
        git lfs pull --include="newsletter.db"
        cp newsletter.db /tmp/newsletter.db
        git checkout main
        cp /tmp/newsletter.db newsletter.db
        ls -lh newsletter.db

        python -m src.init_db

        echo "${_YT_COOKIES_B64}" | base64 --decode > cookies.txt
        export YT_COOKIE_FILE="$(pwd)/cookies.txt"

        echo 'ControlPort 9051' >> /etc/tor/torrc
        service tor start
        sleep 12

        python -m src.articles.embed_articles
        python -m src.articles.rank
        python -m src.articles.summarise
        python -m src.youtube.embed_videos
        python -m src.youtube.youtube_rank
        python -m src.youtube.youtube_summarise
        python -m src.render_newsletter
        python -m src.smtp_mailer
        python -m src.housekeeping

        echo "📊 Database after housekeeping:"; ls -lh newsletter.db

        cp newsletter.db /tmp/newsletter_cleared.db
        rm -f newsletter.db

        git fetch origin data
        git checkout data
        git pull --ff-only origin data
        git lfs install
        cp /tmp/newsletter_cleared.db newsletter.db

        git add newsletter.db || true
        git commit -m "Cleared DB after newsletter $(date --iso-8601=seconds)" || true

        git remote remove push-tmp 2>/dev/null || true
        git remote add push-tmp "https://oauth2:$$_GITHUB_TOKEN@github.com/$$_GITHUB_REPO.git"
        git push push-tmp data

        echo "✅ Newsletter complete and DB cleared!"
    secretEnv: ['_GITHUB_TOKEN', '_GITHUB_REPO', '_YT_COOKIES_B64', '_OPENROUTER_API_KEY', '_YOUTUBE_API_KEY', '_SMTP_USER', '_SMTP_PASS']

# Secrets
availableSecrets:
  secretManager:
    - versionName: projects/${PROJECT_ID}/secrets/github-token/versions/latest
      env: '_GITHUB_TOKEN'
    - versionName: projects/${PROJECT_ID}/secrets/github-repo/versions/latest
      env: '_GITHUB_REPO'
    - versionName: projects/${PROJECT_ID}/secrets/YT_COOKIES_MIN_B64/versions/latest
      env: '_YT_COOKIES_B64'
    - versionName: projects/${PROJECT_ID}/secrets/OPENROUTER_API_KEY/versions/latest
      env: '_OPENROUTER_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/YOUTUBE_API_KEY/versions/latest
      env: '_YOUTUBE_API_KEY'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_USER/versions/latest
      env: '_SMTP_USER'
    - versionName: projects/${PROJECT_ID}/secrets/SMTP_PASS/versions/latest
      env: '_SMTP_PASS'

options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  volumes:
    - name: pip-cache
      path: /root/.cache/pip

timeout: 3600s
